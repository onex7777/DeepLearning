{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.过拟合\n",
    "建模的目的是让模型学习到数据的一般性规律，但有时候可能会学过头，学到一些噪声数据的特性，虽然模型可以在训练集上取得好的表现，但在测试集上结果往往会变差，这时称模型陷入了**过拟合**，接下来造一些伪数据进行演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ml_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c115acb392fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mml_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ml_models'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "from ml_models.linear_model import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#造伪样本\n",
    "X=np.linspace(0,100,100)\n",
    "X=np.c_[X,np.ones(100)]\n",
    "w=np.asarray([3,2])\n",
    "Y=X.dot(w)\n",
    "X=X.astype('float')\n",
    "Y=Y.astype('float')\n",
    "X[:,0]+=np.random.normal(size=(X[:,0].shape))*3#添加噪声\n",
    "Y=Y.reshape(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拟合数据并可视化\n",
    "lr=LinearRegression()\n",
    "lr.fit(X[:,:-1],Y)\n",
    "lr.plot_fit_boundary(X[:,:-1],Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前看起来效果还是可以的，但如果加入几个异常点，再看看效果呢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate([X,np.asanyarray([[100,1],[101,1],[102,1],[103,1],[104,1]])])\n",
    "Y=np.concatenate([Y,np.asanyarray([[3000],[3300],[3600],[3800],[3900]])])\n",
    "lr=LinearRegression()\n",
    "lr.fit(X[:,:-1],Y)\n",
    "lr.plot_fit_boundary(X[:,:-1],Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.正则化\n",
    "可以看到，仅仅加入了几个很离谱的异常点，就会对预测产生很大的影响，且偏离很远，这在实际情况中是很常见的；通常可以通过对模型参数添加正则化约束来避免这种情况，使其不会太“飘”，做法是在loss函数中为权重$w$添加$L_1$或者$L_2$约束，借用上一节的公式推导，直接推出loss部分：  \n",
    "\n",
    "1.线性回归中添加$L_1$约束称为Lasso回归，其损失函数如下：  \n",
    "$$\n",
    "L(w)=\\sum_{i=1}^m(y_i-f(x_i))^2+\\lambda||w||_1\n",
    "$$  \n",
    "2.线性回归中添加$L_2$约束称为Ridge回归，其损失函数如下：  \n",
    "$$\n",
    "L(w)=\\sum_{i=1}^m(y_i-f(x_i))^2+\\alpha||w||_2\n",
    "$$ \n",
    "3.如果不太确定用$L_1$好，还是$L_2$好，可以用它们的组合，称作ElasticNet，损失函数如下：  \n",
    "$$\n",
    "L(w)=\\sum_{i=1}^m(y_i-f(x_i))^2+\\lambda||w||_1+\\alpha||w||_2\n",
    "$$ \n",
    "可以发现通过调整超参，可以控制$w$的大小，如果$\\lambda$或$\\alpha$设置很大，$w$会被约束的很小，而如果$\\alpha$或$\\lambda$设置为0，等价于原始的不带正则项的线性回归；通常可以通过交叉验证，根据验证集上的表现来设置一个合适的超参；接下来在上一节线性回归代码的基础上实现Lasso,Ridge,ElasticNet模型，另外设置两个参数`l1_ratio`以及`l2_ratio`，分别用来控制$L_1$和$L_2$的loss部分的权重\n",
    "### 三.代码实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, fit_intercept=True, solver='sgd', if_standard=True, epochs=10, eta=1e-2, batch_size=1,\n",
    "                 l1_ratio=None, l2_ratio=None):\n",
    "        \"\"\"\n",
    "        :param fit_intercept: 是否训练bias\n",
    "        :param solver:\n",
    "        :param if_standard:\n",
    "        \"\"\"\n",
    "        self.w = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.solver = solver\n",
    "        self.if_standard = if_standard\n",
    "        if if_standard:\n",
    "            self.feature_mean = None\n",
    "            self.feature_std = None\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.batch_size = batch_size\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.l2_ratio = l2_ratio\n",
    "        # 注册sign函数\n",
    "        self.sign_func = np.vectorize(utils.sign)\n",
    "\n",
    "    def init_params(self, n_features):\n",
    "        \"\"\"\n",
    "        初始化参数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.w = np.random.random(size=(n_features, 1))\n",
    "\n",
    "    def _fit_closed_form_solution(self, x, y):\n",
    "        \"\"\"\n",
    "        直接求闭式解\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.l1_ratio is None and self.l2_ratio is None:\n",
    "            self.w = np.linalg.pinv(x).dot(y)\n",
    "        elif self.l1_ratio is None and self.l2_ratio is not None:\n",
    "            self.w = np.linalg.inv(x.T.dot(x) + self.l2_ratio * np.eye(x.shape[1])).dot(x.T).dot(y)\n",
    "        else:\n",
    "            self._fit_sgd(x, y)\n",
    "\n",
    "    def _fit_sgd(self, x, y):\n",
    "        \"\"\"\n",
    "        随机梯度下降求解\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :param epochs:\n",
    "        :param eta:\n",
    "        :param batch_size:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x_y = np.c_[x, y]\n",
    "        # 按batch_size更新w,b\n",
    "        for _ in range(self.epochs):\n",
    "            np.random.shuffle(x_y)\n",
    "            for index in range(x_y.shape[0] // self.batch_size):\n",
    "                batch_x_y = x_y[self.batch_size * index:self.batch_size * (index + 1)]\n",
    "                batch_x = batch_x_y[:, :-1]\n",
    "                batch_y = batch_x_y[:, -1:]\n",
    "\n",
    "                dw = -2 * batch_x.T.dot(batch_y - batch_x.dot(self.w)) / self.batch_size\n",
    "\n",
    "                # 添加l1和l2的部分\n",
    "                dw_reg = np.zeros(shape=(x.shape[1] - 1, 1))\n",
    "                if self.l1_ratio is not None:\n",
    "                    dw_reg += self.l1_ratio * self.sign_func(self.w[:-1]) / self.batch_size\n",
    "                if self.l2_ratio is not None:\n",
    "                    dw_reg += 2 * self.l2_ratio * self.w[:-1] / self.batch_size\n",
    "                dw_reg = np.concatenate([dw_reg, np.asarray([[0]])], axis=0)\n",
    "                dw += dw_reg\n",
    "                self.w = self.w - self.eta * dw\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # 是否归一化feature\n",
    "        if self.if_standard:\n",
    "            self.feature_mean = np.mean(x, axis=0)\n",
    "            self.feature_std = np.std(x, axis=0) + 1e-8\n",
    "            x = (x - self.feature_mean) / self.feature_std\n",
    "        # 是否训练bias\n",
    "        if self.fit_intercept:\n",
    "            x = np.c_[x, np.ones_like(y)]\n",
    "        # 初始化参数\n",
    "        self.init_params(x.shape[1])\n",
    "        # 训练模型\n",
    "        if self.solver == 'closed_form':\n",
    "            self._fit_closed_form_solution(x, y)\n",
    "        elif self.solver == 'sgd':\n",
    "            self._fit_sgd(x, y)\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        输出原始的系数\n",
    "        :return: w,b\n",
    "        \"\"\"\n",
    "        if self.fit_intercept:\n",
    "            w = self.w[:-1]\n",
    "            b = self.w[-1]\n",
    "        else:\n",
    "            w = self.w\n",
    "            b = 0\n",
    "        if self.if_standard:\n",
    "            w = w / self.feature_std.reshape(-1, 1)\n",
    "            b = b - w.T.dot(self.feature_mean.reshape(-1, 1))\n",
    "        return w.reshape(-1), b\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        :param x:ndarray格式数据: m x n\n",
    "        :return: m x 1\n",
    "        \"\"\"\n",
    "        if self.if_standard:\n",
    "            x = (x - self.feature_mean) / self.feature_std\n",
    "        if self.fit_intercept:\n",
    "            x = np.c_[x, np.ones(shape=x.shape[0])]\n",
    "        return x.dot(self.w)\n",
    "\n",
    "    def plot_fit_boundary(self, x, y):\n",
    "        \"\"\"\n",
    "        绘制拟合结果\n",
    "        :param x:\n",
    "        :param y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        plt.scatter(x[:, 0], y)\n",
    "        plt.plot(x[:, 0], self.predict(x), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=LinearRegression(l1_ratio=100)\n",
    "lasso.fit(X[:,:-1],Y)\n",
    "lasso.plot_fit_boundary(X[:,:-1],Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge=LinearRegression(l2_ratio=10)\n",
    "ridge.fit(X[:,:-1],Y)\n",
    "ridge.plot_fit_boundary(X[:,:-1],Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic=LinearRegression(l1_ratio=100,l2_ratio=10)\n",
    "elastic.fit(X[:,:-1],Y)\n",
    "elastic.plot_fit_boundary(X[:,:-1],Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将sign函数整理到ml_models.utils中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
