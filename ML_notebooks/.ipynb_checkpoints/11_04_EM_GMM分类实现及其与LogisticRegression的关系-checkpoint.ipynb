{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先说明一下，这一节其实与EM没多大关系，只是想对GMM的分类作一个实现并推导它与LogisticRegression之间的关系\n",
    "### 一.分类原理\n",
    "分类实现的原理非常简单，对每一个类训练一个高斯模型模型（如果你喜欢，多个也是可以的，这里你就可以使用用EM算法了，将前面的GMMCluster简单封装一下就可以）即可，然后每个类的权重由其样本所占比例确定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# from ml_models.em import GMMCluster\n",
    "\n",
    "\"\"\"\n",
    "利用GMMCluster实现分类，代码封装到ml_models.em\n",
    "\"\"\"\n",
    "\n",
    "class GMMClassifier(object):\n",
    "    def __init__(self, cluster_each_class=1, n_iter=100, tol=1e-3, shr_cov=False):\n",
    "        \"\"\"\n",
    "        :param cluster_each_class:每个类需要几个高斯模型去拟合，默认1个\n",
    "        :param n_iter:迭代次数\n",
    "        :param tol: -log likehold增益<tol时，停止训练\n",
    "        :param shr_cov:是否共享协方差矩阵\n",
    "        \"\"\"\n",
    "        self.cluster_each_class = cluster_each_class\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.shr_cov = shr_cov\n",
    "        self.models = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for y_index in range(y.max() + 1):\n",
    "            new_X = X[y == y_index]\n",
    "            cluster = GMMCluster(n_components=self.cluster_each_class, tol=self.tol, n_iter=self.n_iter)\n",
    "            cluster.fit(new_X)\n",
    "            self.models.append(cluster)\n",
    "        if self.shr_cov:\n",
    "            # 获取所有的协方差矩阵\n",
    "            sigmas = []\n",
    "            for model in self.models:\n",
    "                params = model.params\n",
    "                for param in params:\n",
    "                    sigmas.append(param[2])\n",
    "            # 求平均\n",
    "            ave_sigma = np.mean(sigmas, axis=0)\n",
    "            # 更新\n",
    "            for model in self.models:\n",
    "                params = model.params\n",
    "                for param in params:\n",
    "                    param[2] = ave_sigma\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        W = np.asarray([model.predict_sample_generate_proba(X) for model in self.models]).T\n",
    "        W = W / np.sum(W, axis=1, keepdims=True)\n",
    "        return W\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#造数据\n",
    "from sklearn.datasets import make_blobs\n",
    "# from ml_models import utils\n",
    "\n",
    "X, y = make_blobs(n_samples=400, centers=4, cluster_std=0.85, random_state=0)\n",
    "X = X[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "绘制决策边界\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def plot_decision_function(X, y, clf, support_vectors=None):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    plt.scatter(X[:, 0], X[:, 1], alpha=0.8, c=y, edgecolor='k')\n",
    "    # 绘制支持向量\n",
    "    if support_vectors is not None:\n",
    "        plt.scatter(X[support_vectors, 0], X[support_vectors, 1], s=80, c='none', alpha=0.7, edgecolor='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GMMCluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-14278ef67f94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#训练模型并可视化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGMMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplot_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b8dc05fa6233>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0my_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mnew_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGMMCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_each_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GMMCluster' is not defined"
     ]
    }
   ],
   "source": [
    "#训练模型并可视化\n",
    "gmm = GMMClassifier(n_iter=100)\n",
    "gmm.fit(X, y)\n",
    "plot_decision_function(X, y, gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码里面添加了一个`shr_cov`的超参，如果`shr_cov=True`表示所有的模型都会共享同一个协方差矩阵，我们接下来看看会发生什么"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMMClassifier(n_iter=100,shr_cov=True)\n",
    "gmm.fit(X, y)\n",
    "plot_decision_function(X, y, gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现类与类的边界都变成了**直线**，这时的GMM模型似乎退化成了一个线性模型，这是为什么呢？它这时其实是一个带有一定约束的LogisticRegression模型，接下来我们推推看它们之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.协方差矩阵共享的GMM模型与LogisticRegression的关系\n",
    "以二分类为例进行推导，假如我们训练好了两个分类模型，分别为$C_1,C_2$，那么有：   \n",
    "\n",
    "$$\n",
    "p(x\\mid C_1)=N(x\\mid u_1,\\Sigma)\\\\\n",
    "p(x\\mid C_2)=N(x\\mid u_2,\\Sigma)\\\\\n",
    "p(C_1)+p(C_2)=1\n",
    "$$   \n",
    "所以，高斯混合模型：   \n",
    "\n",
    "$$\n",
    "p(x)=p(C_1)p(x\\mid C_1)+p(C_2)p(x\\mid C_2)\n",
    "$$  \n",
    "\n",
    "接下来，我们转换为判断模型的形式：   \n",
    "\n",
    "$$\n",
    "p(C_1\\mid x)=\\frac{p(C_1)p(x\\mid C_1)}{p(x)}\\\\\n",
    "=\\frac{p(C_1)p(x\\mid C_1)}{p(C_1)p(x\\mid C_1)+p(C_2)p(x\\mid C_2)}\\\\\n",
    "=\\frac{1}{1+exp(-Z)}\n",
    "$$   \n",
    "\n",
    "这里$Z=log\\frac{p(C_1)p(x\\mid C_1)}{p(C_2)p(x\\mid C_2)}$，这里已经看到了LogisticRegression的雏形了，接着，我们将$Z$化简看看：  \n",
    "\n",
    "$$\n",
    "Z=log\\frac{p(C_1)p(x\\mid C_1)}{p(C_2)p(x\\mid C_2)}\\\\\n",
    "=log\\frac{p(x\\mid C_1)}{p(x\\mid C_2)}+log\\frac{p(C_1)}{p(C_2)}\\\\\n",
    "=....省略....\\\\\n",
    "=(u_1-u_2)^T\\Sigma^{-1}x-\\frac{1}{2}u_1^T\\Sigma^{-1}u_1+\\frac{1}{2}u_2^T\\Sigma^{-1}u_2+log\\frac{N_1}{N_2}(N_1,N_2表示1,2类的样本量\\frac{p(C_1)}{p(C_2)}=\\frac{N_1}{N_2})\n",
    "$$  \n",
    "\n",
    "所以，如果令：  \n",
    "$$\n",
    "w^T=(u_1-u_2)^T\\Sigma^{-1}\\\\\n",
    "b=-\\frac{1}{2}u_1^T\\Sigma^{-1}u_1+\\frac{1}{2}u_2^T\\Sigma^{-1}u_2+log\\frac{N_1}{N_2}\n",
    "$$  \n",
    "\n",
    "那么：  \n",
    "\n",
    "$$\n",
    "Z=w^Tx+b\n",
    "$$  \n",
    "\n",
    "那么：  \n",
    "\n",
    "$$\n",
    "p(C_1\\mid x)=\\frac{1}{1+exp(-w^Tx-b)}\n",
    "$$  \n",
    "\n",
    "所以，如果数据量大没必要去训练一个复杂的GMM分类器，就训练一个LR就好啦..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
